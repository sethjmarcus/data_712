DAT$SNAP = as.factor(DAT$SNAP)
DAT$ANXIETY = as.factor(DAT$ANXIETY)
knitr::opts_chunk$set(echo = FALSE)
#Clear R's memory
rm(list=ls())
gc()
#set working directory
directory <- "/home/seth/Documents/ameilia_thesis/"
setwd(directory)
set.seed(150)
options(scipen=999)
#Load packages used
#library(tidyverse) #importing, cleaning, recoding, and analyzing data
library(magrittr) # pipe operator
library(dplyr)
library(survey) #package for creating a survey design object
#library(readr) #package to load csv
library(ipumsr) #for loading IPUMS data
#library(knitr)  #used for kable package for pretty tables in pollster
#library(ggplot2) #package for visuals
#library(scales)
#library(RColorBrewer)
#Load the dataset
DAT <- read.csv("DAT2.IPUMS.19ADULT.csv", stringsAsFactors=FALSE)
#Lets look at the data
head(DAT)
DAT$SNAP = as.factor(DAT$SNAP)
DAT$ANXIETY = as.factor(DAT$ANXIETY)
#Create survey design object
gss.design <- svydesign(
ids = ~PSU,
strata = ~STRATA,
data = DAT,
weights = ~SAMPWEIGHT,
nest = T)
summary(gss.design)
#Create a cross-tab of ANXIETY by SNAP
TAB.1 <- svyby(~ANXIETY, ~SNAP, gss.design, svymean, na.rm = TRUE, ci=TRUE)
TAB.1
#then transform into a data frame
TAB.1b <- as.data.frame(TAB.1)
TAB.1b
#Create a cross-tab of ANXIETY by POVERTY
TAB.2 <- svyby(~ANXIETY, by=~POVERTY.grp, design = gss.design, FUN = svymean, na.rm = T, ci=F)
TAB.2
#then transform into a data frame
TAB.2b <- as.data.frame(TAB.2)
TAB.2b
#DIDN'T RUN PROPERLY--NEED TO CHECK IT AGAIN
#Create a cross-tab of ANXIETY by FOODSEC
#library(survey)
TAB.3 <- svyby(~ANXIETY, ~FOODSEC, gss.design, svymean, na.rm=T, ci=F)
TAB.3
#then transform into a data frame
TAB.3b <- as.data.frame(TAB.3)
TAB.3b
knitr::opts_chunk$set(echo = FALSE)
#Clear R's memory
rm(list=ls())
gc()
#set working directory
directory <- "/home/seth/Documents/ameilia_thesis/"
setwd(directory)
set.seed(150)
options(scipen=999)
#Load packages used
#library(tidyverse) #importing, cleaning, recoding, and analyzing data
library(magrittr) # pipe operator
library(dplyr)
library(survey) #package for creating a survey design object
#library(readr) #package to load csv
library(ipumsr) #for loading IPUMS data
#library(knitr)  #used for kable package for pretty tables in pollster
#library(ggplot2) #package for visuals
#library(scales)
#library(RColorBrewer)
#Load the dataset
DAT <- read.csv("DAT2.IPUMS.19ADULT.csv", stringsAsFactors=FALSE)
#Lets look at the data
head(DAT)
#DAT$SNAP = as.factor(DAT$SNAP)
DAT$ANXIETY = as.factor(DAT$ANXIETY)
#Create survey design object
gss.design <- svydesign(
ids = ~PSU,
strata = ~STRATA,
data = DAT,
weights = ~SAMPWEIGHT,
nest = T)
summary(gss.design)
#determine weighted estimates of Anxiety among all adults
table1 <- svymean(~ANXIETY, gss.design, data = DAT, na.rm=T)
table1
#Create a cross-tab of ANXIETY by SNAP
TAB.1 <- svyby(~ANXIETY, ~SNAP, gss.design, svymean, na.rm = TRUE, ci=TRUE)
TAB.1
#then transform into a data frame
TAB.1b <- as.data.frame(TAB.1)
TAB.1b
#Create a cross-tab of ANXIETY by POVERTY
TAB.2 <- svyby(~ANXIETY, by=~POVERTY.grp, design = gss.design, FUN = svymean, na.rm = T, ci=F)
TAB.2
#then transform into a data frame
TAB.2b <- as.data.frame(TAB.2)
TAB.2b
test = svyby(~ANXIETY, ~FOODSTAT30, gss.design, svymean, na.rm=TRUE, ci=FALSE)
test
test1 = svyby(~ANXIETY, ~RACE.grp, gss.design, svymean, na.rm=TRUE, ci=FALSE)
test1
?svyby
rm(list=ls())
gc()
directory = "~/Documents/Masters/data712/assignment_2/"
setwd(directory)
set.seed(100)
# needed libraries
library("RSocrata")
library("dplyr")
library("tidyr")
library("lubridate")
library("psych")
library("ggplot2")
# read in file/data
restaurant_raw = read.socrata("https://data.cityofnewyork.us/resource/43nn-pn8j.json?$select=camis,zipcode,inspection_date,action,violation_code,violation_description,critical_flag,score,grade,cuisine_description")
rodent_raw = read.socrata("https://data.cityofnewyork.us/resource/p937-wjvj.json?$select=inspection_type,job_ticket_or_work_order_id,zip_code as zipcode,inspection_date,result")
income_raw_2019 = read.csv("ACSST5Y2019S1901Data.csv")
income_2019_filtered = income_raw_2019 %>% select(c('NAME','S1901_C02_012E', 'S1901_C02_013E'))
# Rename columns
names(income_2019_filtered)[names(income_2019_filtered) == 'NAME'] <- 'zipcode'
names(income_2019_filtered)[names(income_2019_filtered) == 'S1901_C02_012E'] <- 'median_income'
names(income_2019_filtered)[names(income_2019_filtered) == 'S1901_C02_013E'] <- 'avg_income'
# clean zipcode column
income_2019_filtered = data.frame(lapply(income_2019_filtered, as.character), stringsAsFactors = FALSE)
income_2019_filtered$zipcode = substr(income_2019_filtered$zipcode
, nchar(income_2019_filtered$zipcode)-4
, nchar(income_2019_filtered))
income_2019_filtered$avg = as.numeric(as.character(income_2019_filtered$avg))
#filtering restaurant data. Only 2019
restaurant_filtered_2019 = restaurant_raw %>% filter(year(inspection_date)==2019)
restaurant_filtered_2019 = restaurant_raw %>%
filter(!is.na(score))
restaurant_filtered_2019$score <- as.numeric(restaurant_filtered_2019$score)
rodent_filtered = rodent_raw %>% filter(year(inspection_date)==2019)
names(zip_code_raw)[names(zip_code_raw) == 'zcta'] <- 'zipcode'
zip_code_raw = read.socrata("https://data.cityofnewyork.us/resource/pri4-ifjk.json")
names(zip_code_raw)[names(zip_code_raw) == 'zcta'] <- 'zipcode'
grouped_rest = restaurant_filtered_2019 %>%
group_by(zipcode) %>%
summarise(avg_score = mean(score))
grouped_rodent = rodent_filtered %>%
group_by(zipcode) %>%
summarise(cnt = n())
View(zip_code_raw)
merge(zip_code_raw$modzcta, income_2019_filtered$zipcode)
?merge
merge(zip_code_raw$modzcta, income_2019_filtered$zipcode, by.x = modzcta, by.y=zipcode, all=T, sort=T)
merge(zip_code_raw, income_2019_filtered, by.x = modzcta, by.y=zipcode, all=T, sort=T)
merge(zip_code_raw, income_2019_filtered, by.x = 'modzcta', by.y='zipcode', all=T, sort=T)
View(merge(zip_code_raw, income_2019_filtered, by.x = 'modzcta', by.y='zipcode', all=T, sort=T))
names(nyc_shape)[names(nyc_shape) == 'zcta'] <- 'zipcode'
nyc_shape <- read_sf(dsn = "/home/seth/Documents/Masters/data712/assignment_2/Modified Zip Code Tabulation Areas (MODZCTA)", layer = "geo_export_0547fb7c-0cef-4818-babc-6cbd021def07")
library(rnaturalearth)
library(maps)
nyc_shape <- read_sf(dsn = "/home/seth/Documents/Masters/data712/assignment_2/Modified Zip Code Tabulation Areas (MODZCTA)", layer = "geo_export_0547fb7c-0cef-4818-babc-6cbd021def07")
library(ggplot2)
library(sf)
nyc_shape <- read_sf(dsn = "/home/seth/Documents/Masters/data712/assignment_2/Modified Zip Code Tabulation Areas (MODZCTA)", layer = "geo_export_0547fb7c-0cef-4818-babc-6cbd021def07")
names(nyc_shape)[names(nyc_shape) == 'zcta'] <- 'zipcode'
result = merge(nyc_shape, income_2019_filtered, by.x = 'modzcta', by.y="zipcode", all.x = TRUE)
result = merge(result, grouped_rest, by="zipcode", all.x = TRUE)
result = merge(result, grouped_rodent, by="zipcode", all.x = TRUE)
#result = result %>%
#  select(c("zipcode", "pop_est","the_geom.type", "the_geom.coordinates", "median_income", "avg_income", "avg_score", #"cnt"))
ggplot(data = result) +
geom_sf(mapping = aes(fill = cnt), show.legend = TRUE) +
geom_sf(fill = NA) +
scale_fill_gradient(
name="placehoder",
na.value="grey100",
low="blue",
high="red"
)+
coord_sf()
merge(zip_code_raw, result, by.x = modzcta, by.y=zipcode, all=T, sort=T)
merge(zip_code_raw, result, by.x = 'modzcta', by.y='zipcode', all=T, sort=T) %>% View()
merge(zip_code_raw, result, by.x = 'modzcta', by.y='zipcode', all.x =T, sort=T) %>% View()
merge(zip_code_raw, result, by.x = 'modzcta', by.y='zipcode', all.y =T, sort=T) %>% View()
View(zip_code_raw)
#names(nyc_shape)[names(nyc_shape) == 'zcta'] <- 'zipcode'
result = merge(nyc_shape, income_2019_filtered, by.x = 'modzcta', by.y="zipcode", all.x = TRUE)
result = merge(result, grouped_rest, by="zipcode", all.x = TRUE)
result = merge(result, grouped_rodent, by="zipcode", all.x = TRUE)
#result = result %>%
#  select(c("zipcode", "pop_est","the_geom.type", "the_geom.coordinates", "median_income", "avg_income", "avg_score", #"cnt"))
View(income_raw_2019)
#names(nyc_shape)[names(nyc_shape) == 'zcta'] <- 'zipcode'
result = merge(nyc_shape, income_2019_filtered, by.x = 'modzcta', by.y="zipcode", all.x = TRUE, all.y = F)
result = merge(result, grouped_rest, by="zipcode", all.x = TRUE)
result = merge(result, grouped_rodent, by="zipcode", all.x = TRUE)
#result = result %>%
#  select(c("zipcode", "pop_est","the_geom.type", "the_geom.coordinates", "median_income", "avg_income", "avg_score", #"cnt"))
ggplot(data = result) +
geom_sf(mapping = aes(fill = cnt), show.legend = TRUE) +
geom_sf(fill = NA) +
scale_fill_gradient(
name="placehoder",
na.value="grey100",
low="blue",
high="red"
)+
coord_sf()
View(result)
nyc_shape <- read_sf(dsn = "/home/seth/Documents/Masters/data712/assignment_2/Modified Zip Code Tabulation Areas (MODZCTA)", layer = "geo_export_0547fb7c-0cef-4818-babc-6cbd021def07")
names(nyc_shape)[names(nyc_shape) == 'modzcta'] <- 'zipcode'
result = merge(nyc_shape, income_2019_filtered, by="zipcode", all.x = TRUE, all.y = F)
result = merge(result, grouped_rest, by="zipcode")
result = merge(result, grouped_rodent, by="zipcode")
#result = result %>%
#  select(c("zipcode", "pop_est","the_geom.type", "the_geom.coordinates", "median_income", "avg_income", "avg_score", #"cnt"))
ggplot(data = result) +
geom_sf(mapping = aes(fill = cnt), show.legend = TRUE) +
geom_sf(fill = NA) +
scale_fill_gradient(
name="placehoder",
na.value="grey100",
low="blue",
high="red"
)+
coord_sf()
ggplot(data = result) +
geom_sf(mapping = aes(fill = cnt), show.legend = TRUE) +
geom_sf(fill = NA) +
scale_fill_gradient(
name="placehoder",
na.value="grey100",
low="blue",
high="red",
trans = log
)+
coord_sf()
?scale_fill_gradient
ggplot(data = result) +
geom_sf(mapping = aes(fill = cnt), show.legend = TRUE) +
geom_sf(fill = NA) +
scale_fill_gradient(
name="placehoder",
na.value="grey100",
low="blue",
high="red",
trans = 'log'
)+
coord_sf()
ggplot(data = result) +
geom_sf(mapping = aes(fill = avg_score), show.legend = TRUE) +
geom_sf(fill = NA) +
scale_fill_gradient(
name="placehoder",
na.value="grey100",
low="blue",
high="red",
trans = 'log'
)+
coord_sf()
ggplot(data = result) +
geom_sf(mapping = aes(fill = avg_score), show.legend = TRUE) +
geom_sf(fill = NA) +
scale_fill_gradient(
name="placehoder",
na.value="grey100",
low="blue",
high="red"
)+
coord_sf()
# Pull out NYC Zip Codes. This will be used with regex later
# See here: https://en.wikipedia.org/wiki/List_of_ZIP_Code_prefixes
nyc_zipcodes_prefixes = c('*100[0-9]{2}', '*101[0-9]{2}', '*102[0-9]{2}', '*103[0-9]{2}', '*104[0-9]{2}', '*110[0-9]{2}','*111[0-9]{2}', '*112[0-9]{2}', '*113[0-9]{2}', '*114[0-9]{2}', '*116[0-9]{2}')
income_2019_filtered = income_raw_2019 %>% select(c('NAME','S1901_C02_012E', 'S1901_C02_013E'))
# Remove zipcodes that don't match the pattern of valid NYC zipcodes.
# TODO: get an actual list of NYC zipcodes and compare to that
income_2019_filtered = income_2019_filtered[grepl(paste(nyc_zipcodes_prefixes, collapse="|"), income_2019_filtered$NAME),]
# Rename columns
names(income_2019_filtered)[names(income_2019_filtered) == 'NAME'] <- 'zipcode'
names(income_2019_filtered)[names(income_2019_filtered) == 'S1901_C02_012E'] <- 'median_income'
names(income_2019_filtered)[names(income_2019_filtered) == 'S1901_C02_013E'] <- 'avg_income'
nyc_zipcodes_prefixes = c('*100[0-9]{2}', '*101[0-9]{2}', '*102[0-9]{2}', '*103[0-9]{2}', '*104[0-9]{2}', '*110[0-9]{2}','*111[0-9]{2}', '*112[0-9]{2}', '*113[0-9]{2}', '*114[0-9]{2}', '*116[0-9]{2}')
income_2019_filtered = income_raw_2019 %>% select(c('NAME','S1901_C02_012E', 'S1901_C02_013E'))
result %>% summarise(n = mean(pop_est))
result %>% mean(pop_est)
?summarise
?mean
?ggsave
rm(list=ls())
gc()
directory = "~/Documents/Masters/data712/assignment_2/"
setwd(directory)
set.seed(100)
# needed libraries
library("RSocrata")
library("dplyr")
library("tidyr")
library("lubridate")
library("psych")
library("ggplot2")
# read in file/data
restaurant_raw = read.socrata("https://data.cityofnewyork.us/resource/43nn-pn8j.json?$select=camis,zipcode,inspection_date,action,violation_code,violation_description,critical_flag,score,grade,cuisine_description")
rodent_raw = read.socrata("https://data.cityofnewyork.us/resource/p937-wjvj.json?$select=inspection_type,job_ticket_or_work_order_id,zip_code as zipcode,inspection_date,result")
income_raw_2019 = read.csv("ACSST5Y2019S1901Data.csv")
# Pull out NYC Zip Codes. This will be used with regex later
# See here: https://en.wikipedia.org/wiki/List_of_ZIP_Code_prefixes
nyc_zipcodes_prefixes = c('*100[0-9]{2}', '*101[0-9]{2}', '*102[0-9]{2}', '*103[0-9]{2}', '*104[0-9]{2}', '*110[0-9]{2}','*111[0-9]{2}', '*112[0-9]{2}', '*113[0-9]{2}', '*114[0-9]{2}', '*116[0-9]{2}')
income_2019_filtered = income_raw_2019 %>% select(c('NAME','S1901_C02_012E', 'S1901_C02_013E'))
# Remove zipcodes that don't match the pattern of valid NYC zipcodes.
# TODO: get an actual list of NYC zipcodes and compare to that
income_2019_filtered = income_2019_filtered[grepl(paste(nyc_zipcodes_prefixes, collapse="|"), income_2019_filtered$NAME),]
# Rename columns
names(income_2019_filtered)[names(income_2019_filtered) == 'NAME'] <- 'zipcode'
names(income_2019_filtered)[names(income_2019_filtered) == 'S1901_C02_012E'] <- 'median_income'
names(income_2019_filtered)[names(income_2019_filtered) == 'S1901_C02_013E'] <- 'avg_income'
income_2019_filtered = data.frame(lapply(income_2019_filtered, as.character), stringsAsFactors = FALSE)
income_2019_filtered$zipcode = substr(income_2019_filtered$zipcode
, nchar(income_2019_filtered$zipcode)-4
, nchar(income_2019_filtered))
income_2019_filtered$avg = as.numeric(as.character(income_2019_filtered$avg))
# Removing invalid Rows
cat("Total: ", nrow(income_2019_filtered))
income_2019_filtered = income_2019_filtered %>% filter(!is.na(income_2019_filtered$avg))
cat("Afer removing invalid Average", nrow(income_2019_filtered))
#filtering restaurant data. Only 2019, only valid zip codes, only valid scores
restaurant_filtered_2019 = restaurant_raw %>%
filter(year(inspection_date)==2019)
print(nrow(restaurant_filtered_2019))
restaurant_filtered_2019 = restaurant_filtered_2019 %>%
filter(!zipcode %in% c('12345',NA))
print(nrow(restaurant_filtered_2019))
restaurant_filtered_2019 = restaurant_filtered_2019 %>%
filter(!is.na(score))
print(nrow(restaurant_filtered_2019))
restaurant_filtered_2019$score <- as.numeric(restaurant_filtered_2019$score)
# group the restaurant scores by zipcode and take the mean
grouped_rest = restaurant_filtered_2019 %>%
group_by(zipcode) %>%
summarise(mean(score))
# Find invalid zip codes
rodent_raw %>%
filter(year(inspection_date) == 2019) %>%
distinct(zipcode) #%>%
#View()
# 0, 10000, 12345, na
# remove rodent inspections that aren't 2019, or have an invalid zip code
rodent_filtered = rodent_raw %>% filter(year(inspection_date)==2019)
print(nrow(rodent_filtered))
rodent_filtered = rodent_filtered %>% filter(!zipcode %in% c('0','10000','12345', NA))
print(nrow(rodent_filtered))
# Sites that had 'Rat Activity'
failed_sites = rodent_filtered %>% filter(result == 'Rat Activity')
grouped_rodents = failed_sites %>%
group_by(zipcode) %>%
summarise(rodent_cnt = n())
# First data merge
merged_data = merge(x=income_2019_filtered, y=grouped_rest, by='zipcode', all=TRUE)
print(nrow(merged_data))
merged_data = merged_data %>%
filter(!is.na(merged_data$`mean(score)`) & !is.na(merged_data$avg))
print(nrow(merged_data))
final_merge = merge(merged_data, grouped_rodents, by='zipcode', all.x=TRUE)
final_merge$rodent_cnt[is.na(final_merge$rodent_cnt)] <- 0
final_merge$avg_income <- as.numeric(final_merge$avg_income)
describe(final_merge)
# There are 6 zip codes that have a rodent count outside of this range. Remove
# them for they are extreme outliers
outlier_val = 235.8+(3*(235.8-6))
temp = final_merge %>% filter(rodent_cnt <= outlier_val)
regression_final = lm(formula= `mean(score)`~avg_income+rodent_cnt, data=final_merge)
summary(regression_final)
describe(temp$rodent_cnt)
regression = lm(formula=`mean(score)`~avg, data=merged_data)
summary(regression)
options(scipen=999)
ggplot(merged_data, aes(x=avg, y=`mean(score)`)) +
geom_point() +
labs(x='Average Income of Zip Code',y='Average Restaurant Health Score',title = 'Average Income by Zip Code vs. Average Restaurant Health Score by Zip Code')+
stat_smooth(method="lm")
ggplot(final_merge, aes(x=avg_income, y=rodent_cnt)) +
geom_point() +
labs(x='Average Income of Zip Code',y='Rodent Count',title = 'Average Income by Zip Code vs. Number of Reported Rodent Sightings\nby Zip Code')+
stat_smooth(method="lm")
ggplot(final_merge, aes(x=`mean(score)`, y=rodent_cnt)) +
geom_point() +
labs(x='Average Income of Zip Code',y='Rodent Count',title = 'Average Restaurant Health Score by Zip Code vs. Number of Reported Rodent\nSightings by Zip Code')+
stat_smooth(method="lm")
lm(formula=`mean(score)`~`rodent_cnt`, data=final_merge) %>% summary()
ggplot(merged_data, aes(x=`mean(score)`)) +
geom_histogram() + #binwidth = 1
#scale_x_continuous(n.breaks=15)
labs(x='Mean Restaurant Health Score per Zip Code', y='Frequency', title='Frequency of Average Restaurant Health Score of Zip Codes in NYC')
# Desrciptive Statistics
ggplot(merged_data, aes(x=avg)) +
geom_histogram(binwidth = 10000) +
labs(x='Mean Income per Zip Code', y='Frequency', title='Frequency of Mean Income of Zip Codes in NYC')+
scale_x_continuous(n.breaks=10)
#options(scipen = 0)
#descriptive statistics
ggplot(temp, aes(x=rodent_cnt)) +
geom_histogram() +
labs(x='Number of Reported Rodent Sightings Resulting in "Rat Activity"', y="Frequency", title='Frequency of Number of Positive Reported Rodent Sightings by Zip Code')
ggplot(final_merge, aes(x=final_merge$avg_income, y=rodent_cnt)) +
geom_point() +
labs(x='Average Income of Zip Code',y='Rodent Count',title = 'Average Restaurant Health Score by Zip Code vs. Number of Reported Rodent\nSightings by Zip Code')+
stat_smooth(method="lm")
ggplot(final_merge, aes(x=avg_income, y=rodent_cnt)) +
geom_point() +
labs(x='Average Income of Zip Code',y='Rodent Count',title = 'Average Restaurant Health Score by Zip Code vs. Number of Reported Rodent\nSightings by Zip Code')+
stat_smooth(method="lm")
?ggplot
?mapping
#descriptive statistics
ggplot(temp, aes(x=rodent_cnt)) +
geom_histogram() +
scale_y_continuous(trans='log1p') +
labs(x='Number of Reported Rodent Sightings Resulting in "Rat Activity"', y="Frequency (log)", title='Log of Frequency of Number of Positive Reported Rodent Sightings by Zip Code')
#descriptive statistics
ggplot(temp, aes(x=rodent_cnt)) +
geom_histogram() +
scale_y_continuous(trans='log10') +
labs(x='Number of Reported Rodent Sightings Resulting in "Rat Activity"', y="Frequency (log)", title='Log of Frequency of Number of Positive Reported Rodent Sightings by Zip Code')
#descriptive statistics
ggplot(temp, aes(x=rodent_cnt)) +
geom_histogram() +
scale_y_continuous(trans='log1p') +
labs(x='Number of Reported Rodent Sightings Resulting in "Rat Activity"', y="Frequency (log)", title='Log of Frequency of Number of Positive Reported Rodent Sightings by Zip Code')
#descriptive statistics
ggplot(temp, aes(x=rodent_cnt)) +
geom_histogram() +
scale_y_continuous(trans='log1p') +
labs(x='Number of Reported Rodent Sightings Resulting in "Rat Activity"', y="Frequency (log(1+x))", title='Log of Frequency of Number of Positive Reported Rodent Sightings by Zip Code')
failed_sites_f = rodents_filtered
failed_sites_f = rodent_filtered
grouped_rodents = failed_sites_f %>%
group_by(zipcode) %>%
summarise(rodent_cnt = n())
# First data merge
merged_data = merge(x=income_2019_filtered, y=grouped_rest, by='zipcode', all=TRUE)
print(nrow(merged_data))
merged_data = merged_data %>%
filter(!is.na(merged_data$`mean(score)`) & !is.na(merged_data$avg))
print(nrow(merged_data))
final_merge = merge(merged_data, grouped_rodents, by='zipcode', all.x=TRUE)
final_merge$rodent_cnt[is.na(final_merge$rodent_cnt)] <- 0
final_merge$avg_income <- as.numeric(final_merge$avg_income)
regression_final = lm(formula= `mean(score)`~avg_income+rodent_cnt, data=final_merge)
summary(regression_final)
regression = lm(formula=`mean(score)`~avg, data=merged_data)
summary(regression)
ggplot(merged_data, aes(x=avg, y=`mean(score)`)) +
geom_point() +
labs(x='Average Income of Zip Code',y='Average Restaurant Health Score',title = 'Average Income by Zip Code vs. Average Restaurant Health Score by Zip Code')+
stat_smooth(method="lm")
ggplot(final_merge, aes(x=avg_income, y=rodent_cnt)) +
geom_point() +
labs(x='Average Income of Zip Code',y='Rodent Count',title = 'Average Income by Zip Code vs. Number of Reported Rodent Sightings\nby Zip Code')+
stat_smooth(method="lm")
ggplot(final_merge, aes(x=avg_income, y=rodent_cnt)) +
geom_point() +
labs(x='Average Income of Zip Code',y='Rodent Count',title = 'Average Restaurant Health Score by Zip Code vs. Number of Reported Rodent\nSightings by Zip Code')+
stat_smooth(method="lm")
# Sites that had 'Rat Activity'
failed_sites = rodent_filtered %>% filter(result == 'Rat Activity')
# used for testing/debugging
grouped_rodents = failed_sites %>%
group_by(zipcode) %>%
summarise(rodent_cnt = n())
# First data merge
merged_data = merge(x=income_2019_filtered, y=grouped_rest, by='zipcode', all=TRUE)
final_merge = merge(merged_data, grouped_rodents, by='zipcode', all.x=TRUE)
final_merge$rodent_cnt[is.na(final_merge$rodent_cnt)] <- 0
final_merge$avg_income <- as.numeric(final_merge$avg_income)
describe(final_merge)
regression_final = lm(formula= `mean(score)`~avg_income+rodent_cnt, data=final_merge)
summary(regression_final)
ggplot(merged_data, aes(x=avg, y=`mean(score)`)) +
geom_point() +
labs(x='Average Income of Zip Code',y='Average Restaurant Health Score',title = 'Average Income by Zip Code vs. Average Restaurant Health Score by Zip Code')+
stat_smooth(method="lm")
# There are 6 zip codes that have a rodent count outside of this range. Remove
# them for they are extreme outliers
outlier_val = 235.8+(3*(235.8-6))
temp = final_merge %>% filter(rodent_cnt <= outlier_val)
ggplot(final_merge, aes(x=`mean(score)`)) +
geom_histogram() + #binwidth = 1
#scale_x_continuous(n.breaks=15)
labs(x='Mean Restaurant Health Score per Zip Code', y='Frequency', title='Frequency of Average Restaurant Health Score of Zip Codes in NYC')
# Desrciptive Statistics
ggplot(final_merge, aes(x=avg)) +
geom_histogram(binwidth = 10000) +
labs(x='Mean Income per Zip Code', y='Frequency', title='Frequency of Mean Income of Zip Codes in NYC')+
scale_x_continuous(n.breaks=10)
#options(scipen = 0)
#descriptive statistics
ggplot(final_merge, aes(x=rodent_cnt)) +
geom_histogram() +
scale_y_continuous(trans='log1p') +
labs(x='Number of Reported Rodent Sightings Resulting in "Rat Activity"', y="Frequency (log(1+x))", title='Log of Frequency of Number of Positive Reported Rodent Sightings by Zip Code')
regression_final_2 = lm(formula= rodent_cnt~`mean(score)`+avg_income, data=final_merge)
summary(regression_final_2)
ggplot(final_merge, x=`mean(score)`, y=rodent_cnt) +
geom_point() +
labs(x='Average Restaurant Health Score',y='Rodent Count',title = 'Average Restaurant Health Score by Zip Code vs. Number of Reported Rodent\nSightings by Zip Code')+
stat_smooth(method="lm")
ggplot(final_merge, aes(x=`mean(score)`, y=rodent_cnt)) +
geom_point() +
labs(x='Average Restaurant Health Score',y='Rodent Count',title = 'Average Restaurant Health Score by Zip Code vs. Number of Reported Rodent\nSightings by Zip Code')+
stat_smooth(method="lm")
