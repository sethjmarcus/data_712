!is.na(score))
restaurant_filtered_2019 = restaurant_raw %>%
filter(year(inspection_date)==2019,
!zipcode %in% c('12345',NA),
!is.na(score))
restaurant_filtered_2019$score <- as.numeric(restaurant_filtered_2019$score)
grouped_rest = restaurant_filtered_2019 %>%
group_by(zipcode) %>%
summarise(mean(score))
grouped_rest %>% View()
merged_data = merge(x=income_2019_filtered, y=grouped_rest, by='zipcode', all=TRUE)
merged_data %>% View()
rm(list=ls())
gc()
directory = "/home/seth/Documents/Masters/data712/assignment_2/"
setwd(directory)
set.seed(100)
# needed libraries
library("RSocrata")
library("dplyr")
library("tidyr")
library("lubridate")
# read in files
restaurant_raw = read.socrata("https://data.cityofnewyork.us/resource/43nn-pn8j.json?$select=camis,zipcode,inspection_date,action,violation_code,violation_description,critical_flag,score,grade")
rodent_raw = read.socrata("https://data.cityofnewyork.us/resource/p937-wjvj.json?$select=inspection_type,job_ticket_or_work_order_id,zip_code as zipcode,inspection_date,result")
income_raw_2019 = read.csv("ACSST5Y2019S1901Data.csv")
# income_raw_2020 = read.csv("ACSST5Y2020S1901Data.csv")
# income_raw_2021 = read.csv("ACSST5Y2021S1901Data.csv")
?subset
# Pull out NYC Zip Codes.
# See here: https://en.wikipedia.org/wiki/List_of_ZIP_Code_prefixes
nyc_zipcodes_prefixes = c('*100[0-9]{2}', '*101[0-9]{2}', '*102[0-9]{2}', '*103[0-9]{2}', '*104[0-9]{2}', '*110[0-9]{2}','*111[0-9]{2}', '*112[0-9]{2}', '*113[0-9]{2}', '*114[0-9]{2}', '*116[0-9]{2}')
income_2019_filtered = income_raw_2019 %>% select(c('NAME','S1901_C02_012E', 'S1901_C02_013E'))
# Remove zipcodes that don't match the pattern of valid NYC zipcodes.
# TODO: get an actual list of NYC zipcodes and compare to that
income_2019_filtered = income_2019_filtered[grepl(paste(nyc_zipcodes_prefixes, collapse="|"), income_2019_filtered$NAME),]
# Rename columns
names(income_2019_filtered)[names(income_2019_filtered) == 'NAME'] <- 'zipcode'
names(income_2019_filtered)[names(income_2019_filtered) == 'S1901_C02_012E'] <- 'median'
names(income_2019_filtered)[names(income_2019_filtered) == 'S1901_C02_013E'] <- 'avg'
income_2019_filtered = data.frame(lapply(income_2019_filtered, as.character), stringsAsFactors = FALSE)
income_2019_filtered$zipcode = substr(income_2019_filtered$zipcode
, nchar(income_2019_filtered$zipcode)-4
, nchar(income_2019_filtered))
# Removing invalid Rows
print("Total: ",nrow(income_2019_filtered))
?print
# Removing invalid Rows
print("Total: " + nrow(income_2019_filtered))
# Removing invalid Rows
cat("Total: ", nrow(income_2019_filtered))
income_2019_filtered = income_2019_filtered %>% subset(avg != '-')
cat("Afer removing invalid Average", nrow(income_2019_filtered))
restaurant_filtered_2019 = restaurant_raw %>%
filter(year(inspection_date)==2019,
!zipcode %in% c('12345',NA),
!is.na(score))
restaurant_filtered_2019$score <- as.numeric(restaurant_filtered_2019$score)
print(nrow(restaurant_filtered_2019))
grouped_rest = restaurant_filtered_2019 %>%
group_by(zipcode) %>%
summarise(mean(score))
merged_data = merge(x=income_2019_filtered, y=grouped_rest, by='zipcode', all=TRUE)
merged_data %>% View()
income_2019_filtered = data.frame(lapply(income_2019_filtered, as.character), stringsAsFactors = FALSE)
income_2019_filtered$zipcode = substr(income_2019_filtered$zipcode
, nchar(income_2019_filtered$zipcode)-4
, nchar(income_2019_filtered))
income_2019_filtered$avg = as.numeric(as.character(income_2019_filtered$avg))
# Removing invalid Rows
cat("Total: ", nrow(income_2019_filtered))
income_2019_filtered = income_2019_filtered %>% subset(avg != '-')
cat("Afer removing invalid Average", nrow(income_2019_filtered))
income_2019_filtered = income_raw_2019 %>% select(c('NAME','S1901_C02_012E', 'S1901_C02_013E'))
# Remove zipcodes that don't match the pattern of valid NYC zipcodes.
# TODO: get an actual list of NYC zipcodes and compare to that
income_2019_filtered = income_2019_filtered[grepl(paste(nyc_zipcodes_prefixes, collapse="|"), income_2019_filtered$NAME),]
# Rename columns
names(income_2019_filtered)[names(income_2019_filtered) == 'NAME'] <- 'zipcode'
names(income_2019_filtered)[names(income_2019_filtered) == 'S1901_C02_012E'] <- 'median'
names(income_2019_filtered)[names(income_2019_filtered) == 'S1901_C02_013E'] <- 'avg'
income_2019_filtered = data.frame(lapply(income_2019_filtered, as.character), stringsAsFactors = FALSE)
income_2019_filtered$zipcode = substr(income_2019_filtered$zipcode
, nchar(income_2019_filtered$zipcode)-4
, nchar(income_2019_filtered))
income_2019_filtered$avg = as.numeric(as.character(income_2019_filtered$avg))
income_2019_filtered %>% View()
income_2019_filtered %>% filter(is.na(income_2019_filtered$avg)) %>% nrow()
# Removing invalid Rows
cat("Total: ", nrow(income_2019_filtered))
income_2019_filtered = income_2019_filtered %>% filter(!is.na(income_2019_filtered$avg))
cat("Afer removing invalid Average", nrow(income_2019_filtered))
restaurant_filtered_2019 = restaurant_raw %>%
filter(year(inspection_date)==2019,
!zipcode %in% c('12345',NA),
!is.na(score))
restaurant_filtered_2019$score <- as.numeric(restaurant_filtered_2019$score)
print(nrow(restaurant_filtered_2019))
grouped_rest = restaurant_filtered_2019 %>%
group_by(zipcode) %>%
summarise(mean(score))
merged_data = merge(x=income_2019_filtered, y=grouped_rest, by='zipcode', all=TRUE)
merged_data %>% View()
merged_data %>% filter(is.na(merged_data$`mean(score)`) %>%  nrow()
merged_data %>% filter(is.na(merged_data$`mean(score)`) %>% nrow() %>% print()
merged_data %>%
filter(is.na(merged_data$`mean(score)`)) %>%
nrow()
merged_data %>%
filter(is.na(merged_data$`mean(score)`) | is.na(merged_data$avg)) %>%
nrow()
# Removes 40 entries
merged_data = merged_data %>%
filter(is.na(merged_data$`mean(score)`) | is.na(merged_data$avg))
lm(merged_data$avg~merged_data$`mean(score)`, merged_data)
merged_data = merge(x=income_2019_filtered, y=grouped_rest, by='zipcode', all=TRUE)
# Removes 40 entries
print(nrow(merged_data))
merged_data = merged_data %>%
filter(!is.na(merged_data$`mean(score)`) | is.na(merged_data$avg))
print(nrow(merged_data))
lm(merged_data$avg~merged_data$`mean(score)`, merged_data)
library(ggplot2)
ggplot(merged_data, aes(x=avg, y=`mean(score)`)) +
geom_point() +
stat_smooth(method="lm")
merged_data = merge(x=income_2019_filtered, y=grouped_rest, by='zipcode', all=TRUE)
# Removes 12 entries
print(nrow(merged_data))
merged_data = merged_data %>%
filter(!is.na(merged_data$`mean(score)`) | !is.na(merged_data$avg))
print(nrow(merged_data))
lm(merged_data$avg~merged_data$`mean(score)`, merged_data)
library(ggplot2)
ggplot(merged_data, aes(x=avg, y=`mean(score)`)) +
geom_point() +
stat_smooth(method="lm")
merged_data = merge(x=income_2019_filtered, y=grouped_rest, by='zipcode', all=TRUE)
print(nrow(merged_data))
merged_data = merged_data %>%
filter(!is.na(merged_data$`mean(score)`) & !is.na(merged_data$avg))
print(nrow(merged_data))
lm(merged_data$avg~merged_data$`mean(score)`, merged_data)
library(ggplot2)
ggplot(merged_data, aes(x=avg, y=`mean(score)`)) +
geom_point() +
stat_smooth(method="lm")
lm(formula=merged_data$avg~merged_data$`mean(score)`, data=merged_data)
regression = lm(formula=merged_data$avg~merged_data$`mean(score)`, data=merged_data)
str(regression)
regression %>% View()
regression
summary(regression)
restaurant_raw %>% filter(year(inspection_date)==2019) %>% distinct(camis) %>% nrow()
restaurant_raw %>% filter(year(inspection_date)==2019) %>% nrow()
View(restaurant_raw)
View(restaurant_raw)
View(restaurant_filtered_2019)
restaurant_filtered_2019 = restaurant_raw %>%
filter(year(inspection_date)==2019)
print(nrow(restaurant_filtered_2019))
restaurant_filtered_2019 = restaurant_filtered_2019 %>%
filter(!zipcode %in% c('12345',NA))
print(nrow(restaurant_filtered_2019))
restaurant_filtered_2019 = restaurant_filtered_2019 %>%
filter(!is.na(score))
print(nrow(restaurant_filtered_2019))
restaurant_filtered_2019$score <- as.numeric(restaurant_filtered_2019$score)
summary(merged_data$avg)
merged_data$avg.hist()
merged_data$avg %>% hist()
ggplot(merged_data, aes(x=avg)) +
geom_histogram()
options(scipen = 0)
options(scipen=999)
ggplot(merged_data, aes(x=avg)) +
geom_histogram()
#options(scipen = 0)
options(scipen=999)
ggplot(merged_data, aes(x=`mean(score)`)) +
geom_histogram()
summary(merged_data$`mean(score)`)
?summary
summary.lm(merged_data$avg)
summary.lm(merged_data)
library(psych)
describe(merged_data)
describe(merged_data)
options(scipen=999)
ggplot(merged_data, aes(x=avg)) +
geom_histogram() +
xlab('Mean Income per Zip Code') +
ylab('Frequency') +
title('Frequency of Mean Income by Zip Code in NYC')
ggplot(merged_data, aes(x=avg)) +
geom_histogram() +
labs(x='Mean Income per Zip Code', y='Frequency', title='Frequency of Mean Income by Zip Code in NYC')
options(scipen=999)
ggplot(merged_data, aes(x=avg)) +
geom_histogram() +
labs(x='Mean Income per Zip Code', y='Frequency', title='Frequency of Mean Income of Zip Codes in NYC')
#options(scipen = 0)
ggplot(merged_data, aes(x=avg)) +
geom_histogram(binwidth = 50000) +
labs(x='Mean Income per Zip Code', y='Frequency', title='Frequency of Mean Income of Zip Codes in NYC')+
#options(scipen = 0)
```
options(scipen=999)
ggplot(merged_data, aes(x=avg)) +
geom_histogram(binwidth = 50000) +
labs(x='Mean Income per Zip Code', y='Frequency', title='Frequency of Mean Income of Zip Codes in NYC')
#options(scipen = 0)
ggplot(merged_data, aes(x=avg)) +
geom_histogram() +
labs(x='Mean Income per Zip Code', y='Frequency', title='Frequency of Mean Income of Zip Codes in NYC')
ggplot(merged_data, aes(x=avg)) +
geom_histogram(binwidth = 10000) +
labs(x='Mean Income per Zip Code', y='Frequency', title='Frequency of Mean Income of Zip Codes in NYC')
ggplot(merged_data, aes(x=avg)) +
geom_histogram(binwidth = 10000) +
labs(x='Mean Income per Zip Code', y='Frequency', title='Frequency of Mean Income of Zip Codes in NYC')+
scale_x_continuous(n.breaks=10)
options(scipen=999)
ggplot(merged_data, aes(x=`mean(score)`)) +
geom_histogram() +
labs(x='Mean Restaurant Health Score per Zip Code', y='Frequency', title='Frequency of Average Restaurant Health Score of Zip Codes in NYC')
options(scipen=999)
ggplot(merged_data, aes(x=`mean(score)`)) +
geom_histogram(binwidth = 5) +
labs(x='Mean Restaurant Health Score per Zip Code', y='Frequency', title='Frequency of Average Restaurant Health Score of Zip Codes in NYC')
options(scipen=999)
ggplot(merged_data, aes(x=`mean(score)`)) +
geom_histogram(binwidth = 1) +
labs(x='Mean Restaurant Health Score per Zip Code', y='Frequency', title='Frequency of Average Restaurant Health Score of Zip Codes in NYC')
options(scipen=999)
ggplot(merged_data, aes(x=`mean(score)`)) +
geom_histogram(binwidth = 1) +
scale_x_continuous(n.breaks=30)
labs(x='Mean Restaurant Health Score per Zip Code', y='Frequency', title='Frequency of Average Restaurant Health Score of Zip Codes in NYC')
options(scipen=999)
ggplot(merged_data, aes(x=`mean(score)`)) +
geom_histogram() + #binwidth = 1
scale_x_continuous(n.breaks=30)
labs(x='Mean Restaurant Health Score per Zip Code', y='Frequency', title='Frequency of Average Restaurant Health Score of Zip Codes in NYC')
options(scipen=999)
ggplot(merged_data, aes(x=`mean(score)`)) +
geom_histogram() + #binwidth = 1
scale_x_continuous(n.breaks=15)
labs(x='Mean Restaurant Health Score per Zip Code', y='Frequency', title='Frequency of Average Restaurant Health Score of Zip Codes in NYC')
options(scipen=999)
ggplot(merged_data, aes(x=`mean(score)`)) +
geom_histogram() + #binwidth = 1
#scale_x_continuous(n.breaks=15)
labs(x='Mean Restaurant Health Score per Zip Code', y='Frequency', title='Frequency of Average Restaurant Health Score of Zip Codes in NYC')
library(ggplot2)
ggplot(merged_data, aes(x=avg, y=`mean(score)`)) +
geom_point() +
labs(x='Average Income of Zip Code',y='Average Restaurant Health Score',title = 'Average Income of Zip Code vs. Average Restaurant Health Score')+
stat_smooth(method="lm")
ggplot(merged_data, aes(x=avg, y=`mean(score)`)) +
geom_point() +
labs(x='Average Income of Zip Code',y='Average Restaurant Health Score',title = 'Average Income by Zip Code vs. Average Restaurant Health Score by Zip Code')+
stat_smooth(method="lm")
library(survey)
library("survey")
pearson = svycor(~`mean(score)`+avg, merged_data, sig.stats=TRUE)
pearson = svycor(~`mean(score)`+avg, merged_data, sig.stats=TRUE)
# needed libraries
library("RSocrata")
library("dplyr")
library("tidyr")
library("lubridate")
library("psych")
library("survey")
library("psych")
# Find invalid zip codes
rodent_raw %>%
filter(year(inspection_date) == 2019) %>%
distinct(zipcode) %>%
View()
# 0, 00000, 10000, 12345, 458, na
rodent_filtered = rodent_raw %>% filter(!zipcode %in% c('0','10000','12345', NA), year(inspection_date)==2019)
print(nrow(rodent_filtered))
rodent_filtered %>% distinct(result) %>% View()
failed_sites = rodent_filtered %>% filter(result == 'Rat Activity')
grouped_rodents = failed_sites %>%
group_by(zipcode) %>%
summarise(rodent_cnt = n())
final_merge = merge(merged_data, grouped_rodents, by='zipcode', all=TRUE)
final_merge %>% View()
final_merge$rodent_cnt[is.na(final_merge$rodent_cnt)] <- 0
final_merge %>% View()
?merge
final_merge = merge(merged_data, grouped_rodents, by='zipcode', all=FALSE)
final_merge$rodent_cnt[is.na(final_merge$rodent_cnt)] <- 0
final_merge %>% View()
final_merge = merge(merged_data, grouped_rodents, by='zipcode', all.x=TRUE)
final_merge$rodent_cnt[is.na(final_merge$rodent_cnt)] <- 0
final_merge %>% View()
regression_final = lm(formula= $`mean(score)`~$avg+$rodent_cnt, data=final_merge)
regression_final = lm(formula= `mean(score)`~avg+rodent_cnt, data=final_merge)
summary(regression_final)
regression = lm(formula=merged_data$`mean(score)`~merged_data$avg, data=merged_data)
summary(regression)
regression = lm(formula=`mean(score)`~avg, data=merged_data)
summary(regression)
lm(formula=`mean(score)`~rodent_cnt, data=final_merge) %>% summary()
View(grouped_rodents)
ggplot(data=grouped_rodents, aes=(x=rodent_cnt)) +
geom_histogram()
ggplot(data=grouped_rodents, aes=(y=rodent_cnt)) +
geom_histogram()
ggplot(data=grouped_rodents, aes=(x=rodent_cnt)) +
geom_histogram()
ggplot(grouped_rodents, aes(x=rodent_cnt)) +
geom_histogram()
rodent_filtered = rodent_raw %>% filter(!zipcode %in% c('0','10000','12345', NA))
print(nrow(rodent_filtered))
rodent_filtered = rodent_filtered %>% filter(year(inspection_date)==2019)
print(nrow(rodent_filtered))
rodent_filtered = rodent_filtered %>% filter(year(inspection_date)==2019)
print(nrow(rodent_filtered))
rodent_filtered = rodent_raw %>% filter(!zipcode %in% c('0','10000','12345', NA))
print(nrow(rodent_filtered))
rodent_filtered = rodent_raw %>% filter(year(inspection_date)==2019)
print(nrow(rodent_filtered))
rodent_filtered = rodent_filtered %>% filter(!zipcode %in% c('0','10000','12345', NA))
print(nrow(rodent_filtered))
describe(final_merge)
temp = final_merge %>% filter(rodent_cnt <= 1000)
regression_final = lm(formula= `mean(score)`~avg+rodent_cnt, data=temp)
summary(regression_final)
ggplot(temp, aes(x=rodent_cnt)) +
geom_histogram()
summary(final_merge)
outlier_val = 235.8+(1.5*(235.8-6))
temp = final_merge %>% filter(rodent_cnt <= outlier_val)
regression_final = lm(formula= `mean(score)`~avg+rodent_cnt, data=temp)
summary(regression_final)
ggplot(temp, aes(x=rodent_cnt)) +
geom_histogram()
#left join
final_merge = merge(merged_data, grouped_rodents, by='zipcode', all.x=TRUE)
# Set NAs to 0, for if there are no reports, that means there were 0 reported active sightings
final_merge$rodent_cnt[is.na(final_merge$rodent_cnt)] <- 0
ggplot(temp, aes(x=rodent_cnt)) +
geom_histogram()
summarise(final_merge)
ggplot(final_merge, aes(x=rodent_cnt)) +
geom_histogram()
summarise(final_merge)
summarise(final_merge$rodent_cnt)
summary(final_merge)
ggplot(final_merge, aes(x=rodent_cnt)) +
geom_histogram() +
labs(x='Number of Reported Rodent Sightings Resulting in "Rat Activity"', y="Frequency", title='Frequency of Number of Reported Rodent Sightings Resulting in "Rat Activity" by Zip Code')
ggplot(final_merge, aes(x=rodent_cnt)) +
geom_histogram() +
labs(x='Number of Reported Rodent Sightings Resulting in "Rat Activity"', y="Frequency", title='Frequency of Number of Positive Reported Rodent Sightings by Zip Code')
outlier_val = 235.8+(3*(235.8-6))
temp = final_merge %>% filter(rodent_cnt <= outlier_val)
regression_final = lm(formula= `mean(score)`~avg+rodent_cnt, data=temp)
summary(regression_final)
ggplot(temp, aes(x=rodent_cnt)) +
geom_histogram() +
labs(x='Number of Reported Rodent Sightings Resulting in "Rat Activity"', y="Frequency", title='Frequency of Number of Positive Reported Rodent Sightings by Zip Code')
summary(temp)
describe(temp$rodent_cnt)
regression_final = lm(formula= `mean(score)`~avg+rodent_cnt, data=temp)
summary(regression_final)
rm(list=ls())
gc()
directory = "~/Documents/Masters/data712/assignment_3/"
setwd(directory)
set.seed(100)
# Read in libraries
library(readxl)
oced_data = read_excel(path = "/OECDFamilies.xlsx", sheet=2)
oced_data = read_excel("/OECDFamilies.xlsx", sheet=2)
oced_data = read_excel("OECDFamilies.xlsx", sheet=2)
?read_excel
oced_data = read_excel("OECDFamilies.xlsx", sheet=2)
names(oced_data)
oced_data[order(oced_data$mleave, decreasing = TRUE), ]
oced_data[order(oced_data$mleave, decreasing = TRUE), ] %>% select(cname, mleave)
library(dplyr)
oced_data[order(oced_data$mleave, decreasing = TRUE), ] %>% select(cname, mleave)
oced_data[order(oced_data$mleave, decreasing = TRUE), ] %>% plot()
oced_data[order(oced_data$mleave, decreasing = TRUE), ] %>% hist()
oced_data[order(oced_data$mleave, decreasing = TRUE), ] %>% select(mleave) %>% hist()
oced_data[order(oced_data$mleave, decreasing = TRUE), ] %>% select(mleave)
oced_data[order(oced_data$mleave, decreasing = TRUE), ] %>% select(as.numeric(mleave)) %>% hist()
oced_data[order(oced_data$mleave, decreasing = TRUE), ] %>% select(mleave) %>% hist()
oced_data[order(oced_data$mleave, decreasing = TRUE), ] %>% hist(select(mleave))
oced_data[order(oced_data$mleave, decreasing = TRUE), ] %>% plot(select(mleave))
select(oced_data[order(oced_data$mleave, decreasing = TRUE), ],mleave) %>% plot()
select(oced_data[order(oced_data$mleave, decreasing = TRUE), ],mleave) %>% hist()
regression = lm(unempl.y~mleave+emp.allmoms, data=oced_data)
summary(regression)
?qqnorm
plot(regression)
hist(oced_data$unempl.y)
hist(oced_data$mleave)
hist(oced_data$emp.allmoms)
library(MASS)
library(MASS)
# Read in libraries
library(readxl)
library(dplyr)
oced_data[order(oced_data$mleave, decreasing = TRUE), ] %>% select(cname, mleave)
oced_data[order(oced_data$mleave, decreasing = TRUE), ] #%>% select(cname, mleave)
oced_data[order(oced_data$mleave, decreasing = TRUE), ] %>% select(c(cname, mleave))
oced_data[order(oced_data$mleave, decreasing = TRUE), ] %>% select(c('cname', 'mleave'))
oced_data[order(oced_data$mleave, decreasing = TRUE), ] %>% select('cname', 'mleave')
oced_data[order(oced_data$mleave, decreasing = TRUE), ]
resid.1 = studres(regression)
summary(resid.1)
hist(resid.1)
qqnorm(resid.1)
qqline(resid.1)
hist(x = unempl.y, data=oced_data)
hist(data=oced_data$unempl.y)
hist(x=oced_data$unempl.y)
hist(x=log(oced_data$unempl.y))
hist(x=log(oced_data$unempl.y))
hist(x=oced_data$unempl.y)
hist(x=log(oced_data$mleave))
hist(x=oced_data$mleave)
hist(x=log(oced_data$emp.allmoms))
hist(x=oced_data$emp.allmoms)
hist(x=log(oced_data$unempl.y))
hist(x=oced_data$unempl.y)
hist(x=log(oced_data$mleave))
hist(x=oced_data$mleave)
hist(x=log(oced_data$emp.allmoms))
hist(x=oced_data$emp.allmoms)
regression.2 = lm(log(unempl.y)~log(mleave)+emp.allmoms, data=oced_data)
regression.2 = lm(log(unempl.y)~log(mleave+1)+emp.allmoms, data=oced_data)
summary(regression.2)
# Calculate predicted values
p.1 = predict(regression)
# Standardized predicted values
std.p.1 = (p.1-mean(p.1))/sd(p.1)
# Calculate the residuals
r.1 = resid(regression)
# Standardize the residuals
std.r.1 <- (r.1 - mean(r.1))/sd(r.1)
# Plot the two as a scatterplot with an additional like along y (residuals) = 0
plot(std.p.1,std.r.1,xlab="Standardized Predicted Values",ylab="Standarized Residuals")abline(0,0)
# Calculate predicted values
p.1 = predict(regression)
# Standardized predicted values
std.p.1 = (p.1-mean(p.1))/sd(p.1)
# Calculate the residuals
r.1 = resid(regression)
# Standardize the residuals
std.r.1 <- (r.1 - mean(r.1))/sd(r.1)
# Plot the two as a scatterplot with an additional like along y (residuals) = 0
plot(std.p.1,std.r.1,xlab="Standardized Predicted Values",ylab="Standarized Residuals",abline(0,0))
library(lmtest)
install.packages("lmtest")
library(lmtest)
bptest(regression)
library(usdm)
install.packages("usdm")
library(usdm)
library(usdm)
install.packages("usdm")
install.packages("usdm")
library(usdm)
pred.1 = regression$model[-1,1]
vif(pred.1)
pred.1 = regression$model[-1,1]
usdm::vif(pred.1)
remove.packages("usdm")
library(car)
pred.1 = regression$model[-1,1]
vif(pred.1)
pred.1 = regression$model[-1,1]
#vif(pred.1)
pred.1 = regression$model[-1,1]
vif(pred.1)
pred.1 = regression$model[-1,1]
vif(regression)
leveragePlots(regression)
leveragePlots(regression )
car::outlier.test(cookd(regression))
car::outlierTest(cookd(regression))
car::outlierTest(cooks.distance(regression))
cooksd = cooks.distance(regression)
cooksd = cooks.distance(regression)
# Plot the Cook's Distance using the traditional 4/n criterion
sample_size <- nrow(cars2)
cooksd = cooks.distance(regression)
# Plot the Cook's Distance using the traditional 4/n criterion
sample_size <- nrow(oced_data)
plot(cooksd, pch="*", cex=2, main="Influential Obs by Cooks distance")  # plot cook's distance
abline(h = 4/sample_size, col="green")  # add cutoff line
text(x=1:length(cooksd)+1, y=cooksd, labels=ifelse(cooksd>4/sample_size, names(cooksd),""), col="green")  # add labels
crPlot(regression)
crPlots(regression)
View(oced_data)
View(oced_data %>% select(c(mleave, emp.allmoms, unempl.y)))
oced_data %>% select(c(mleave, emp.allmoms, unempl.y)) %>% View()
oced_data %>% select(c(mleave, emp.allmoms, unempl.y))
oced_data %>% select(c('mleave', 'emp.allmoms', 'unempl.y'))
oced_data %>% dplyr::select(c('mleave', 'emp.allmoms', 'unempl.y'))
oced_data %>% dplyr::select(c('mleave', 'emp.allmoms', 'unempl.y')) %>% View()
oced_data %>% dplyr::select(c(cname, 'mleave', 'emp.allmoms', 'unempl.y')) %>% View()
subset_oced_data = oced_data %>% filter(cname != 'Spain')
regression.3 = lm(unempl.y~mleave+emp.allmoms, data=subset_oced_data)
summary(regression.3)
